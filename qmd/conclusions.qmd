# Conclusions and Recommendations {#sec-conclusions}

{{< include _setup.qmd >}}

As discussed in @sec-literature, there is a large base of literature discussing activity- and trip-based models and their differences, but much of that literature focuses primarily on the technical aspects of the respective models.
There is little research into the practicality of either model type that would be useful to an agency in deciding which type to use.
Therefore, while some of the conclusions presented here address quantitative differences between the two models, the more relevant discussion in this chapter relates to the subjective experience of configuring and using each model.

Specifically, this section focuses on potential "pain points" an agency may encounter when transitioning from a trip-based model to an ABM, both as discussed in the literature and from our experience in this research.
@miller_current_2023 notes several reasons agencies may not be adopting ABMs, as discussed in @sec-literature-lack-of-adpotion.
Some of these reasons include computational inefficiency, complicated design, and lack of interoperability between areas.
Additionally, switching to an ABM would require an agency to expend resources on staff training, though notably this is true for switching to any new modeling system, regardless of model type.
The following sections address each of these difficulties in detail, and discusses our experience as it relates to them.
Note that many of the conclusions presented here are specific to the WFRC model and our ActivitySim implementation, though many conclusions can apply to trip- and/or activity-based models more broadly.

## Computational Resources

The first potential difficulty for an agency transitioning to an ABM is the computational resources required to run the model.
This section discusses the hardware used to run both models in our research, as well as the model runtimes.

All runs of the WFRC model were done on a Windows 10 computer with 2 Intel Xeon Silver 4114 CPUs.
The CPUs have a base frequency of 2.2 GHz with a maximum turbo frequency of 3.0 GHz, and 10 cores/20 threads each.
The WFRC model is configured for multiprocessing in its destination and mode choice steps, and was configured to use 16 threads for our scenario runs.
Notably, this is a specialized computer, but would not be prohibitively expensive to most agencies.

There were not significant differences in runtimes between each model scenario, and each scenario had a runtime of 16–17 hours.
However, this runtime includes the distribution feedback loop (including both trip distribution and a preliminary network assignment each iteration) and the network assignment step of the WFRC model.
While ActivitySim does have a destination choice model analogous to the WFRC model’s trip distribution step, ActivitySim has no distribution feedback loop, as there is no preliminary network assignment.
ActivitySim also does not include a final assignment step.
A better runtime to report for the WFRC model ignores the time spent in the distribution feedback loop (except for one iteration of trip distribution) and the network assignment step.
The entire distribution feedback loop took around 4 hours to complete, and the trip distribution step took 1–2 minutes each iteration.
Additionally, the final network assignment step took around 2 hours, and so the runtime of the WFRC model to compare with ActivitySim is 10–11 hours.

Most runs of ActivitySim were done on parallel computing nodes hosted by Brigham Young University.
Each node runs Red Hat Enterprise Linux 7.9, and uses an AMD EPYC 7763 CPU at 2.45 GHz.
Each ActivitySim run requested 12 CPU cores and 360 GB of RAM.
A dedicated workstation with similar resources would again be a specialized computer, but again not prohibitively expensive.
Running in single-threaded mode (i.e. only one CPU core was utilized), each run took roughly 5 hours to complete, and used nearly all of the 360 GB of RAM available.
With multi-threading enabled, however, the runtimes decreased to around an hour per scenario, using 72% of the available CPU time across all 12 cores and 88% of the available RAM.
This is a huge difference in runtime between the two models, though crucially ActivitySim had 3 times as much RAM available for use.

ActivitySim can significantly reduce the RAM required, at the expense of increased runtimes, through "chunking" options [@asim-chunking], where large tables are loaded into RAM in chunks rather than all at once.
For comparison, we ran the baseline scenario in ActivitySim on the same computer used for the WFRC model scenarios, with chunking enabled to account for the amount of RAM available.
With multi-threading set to use 16 threads, and the chunk size set to 112 GB, the baseline ActivitySim scenario ran in about 13 hours.

ActivitySim completed its scenario runs in a similar time to the WFRC model on the same hardware. This is counter to the idea that ABMs require significantly increased resource and runtimes compared to trip-based models.
Notably, our experience is certainly not universal, and the runtime of any model will greatly depend on several factors, including the specific modeling software and the hardware configuration.
But at least in our case, ActivitySim performed similarly to the WFRC model with the same hardware, and was an order of magnitude faster when provided with enough RAM to avoid chunking.

Based on these results, an agency looking to switch to an ABM would likely not need additional computational resources beyond those used for trip-based models.
However, considering the potential gains in runtime (in the case of ActivitySim, given enough RAM to avoid chunking), it may be worth considering buying or renting additional computational resources.
Computer hardware prices certainly change over time, but as of early 2024, a 12-core, 360 GB RAM computer (using very rough price estimates) would likely cost a few thousand dollars.
Depending on the budget of a given agency, this expense may be worthwhile.

## Complication of Model Design

The second potential difficulty is the complication of an ABM's design.
ABMs may in theory be more complicated than trip-based models, as ABMs model individuals rather than simply using aggregate values.
ABMs therefore have more "moving parts" than trip-based models.
However, these "parts" are often much more straightforward to interpret in an ABM, as each model step simply assigns a household or individual a specific value, such as vehicle ownership or the individual's DAP.
These assigned values can then be used in subsequent model steps.
In our ActivitySim implementation, for example, an individual's distance to work has a direct effect on their remote work status, which in turn affects the DAP assigned to that individual.
It is easy to then model a remote work "rebound effect"[^conclusions-2] by increasing the utility of a non-mandatory DAP for individuals who work remotely.

[^conclusions-2]: See @sec-remote-work-considerations

Since trip-based models exclusively deal with aggregate data, the interpretation of each model step is more vague.
For example, while it may be possible in a trip-based model to model distance to work as it relates to remote work, it is not clear how best to do this, and may require a separate trip purpose and/or trip distribution model specifically for remote work.
If a separate “remote work” trip purpose is used, then the trip generation step must generate a number of remote work “trips,” which is somewhat paradoxical.
In ActivitySim, on the other hand, distance to work is simply another model step that "slots in" to the model pipeline.
This step (and most model steps) can be adjusted and calibrated independently of the rest of the model, and it is much easier to understand and interpret what each model step is doing.

Another example that highlights the difference in interpretation between models regards non--home-based trips.
Trip-based models model non--home-based trips quite abstractly, especially if (like the WFRC model) the model does not include a non--home-based trip redistribution step.
While the idea of a trip that does not begin or end at home is conceptually simple, it is difficult to model concretely in a trip-based model.
Homes may "produce" non--home-based trips, but it is not clear where the origins or destinations of those trips should be.
By contrast, the interpretation of non--home-based trips in an ABM is trivial.
Because trips in an ABM are organized into tours, it is easy to "follow" an individual throughout the day; each trip has an origin and destination consistent with the other trips in the tour.
"Non--home-based" trips are not really a concept in ABMs, as individuals simply make trips, some of which begin or end at home.

A point worth noting, though, is that ABMs do require additional input data compared to a trip-based model.
However, essentially the only additional input data needed for ActivitySim over the WFRC model is the synthetic population (see @sec-activitysim).
While the synthetic population did require a significant amount of initial configuration, modifying the synthetic population (e.g., for the Land Use scenario) did not require much additional effort.

## Model Interoperability

A third potential difficulty is the interoperability/transferability of an ABM from one area to another.
Collaboration between agencies could be difficult if each ABM implementation is bespoke and tailored to a specific area.
We found, however, that at least with ActivitySim this is not the case.
In fact, ActivitySim is relatively easy to customize and extend.
Our ActivitySim implementation originally did not include remote work submodels, but it was simple to copy the remote work models from the Michigan example configuration into our implementation.
Some minor changes were made to ensure consistent variable names, but this process was not very involved (see @tbl-time-spent).
Additionally, the example remote work models did not include provisions for different remote work rates based on job industry as in the WFRC model, but it was simple to add these.[^conclusions-3]

[^conclusions-3]: The synthetic population we created has information on job industry for each worker, and so this was referenced in the remote work submodel in ActivitySim.

The WFRC model does already include different remote work rates by job industry, but it would be difficult to add in different rates based on, for example, vehicle ownership or TAZ average income.
It is worth noting though that this difficulty may be a result of the specific way that the WFRC model is written, and may not apply equally to all trip-based models.

## Training Requirements

In order to change from a trip-based to an ABM, an agency will need to spend time to understand the model and train its staff.
We analyzed the time spent on each part of the modeling process for this project, and this section provides discussion on this.
Obviously the actual time an agency would require to transition to and use an ABM depends on many factors such as specific staff experience, but this section is intended to give a very rough approximation of the time and effort needed.

@tbl-time-spent shows the amount of time spent on creating and analyzing each scenario in both models.
These are approximations, as detailed time logs are not available.
Additionally, many of the tasks are interrelated or use the same code between models and scenarios, so it is sometimes hard to separate the time spent into individual tasks.
However, @tbl-time-spent should serve to give a very rough idea of the time spent on each task.
Note as well that this table shows time spent by one graduate and one undergraduate research assistant; more experienced modelers would likely require significantly less time to create and analyze similar scenarios.

```{r}
#| label: tbl-time-spent
#| tbl-cap: Estimated Time Spent on Modeling Tasks

targets::tar_read(time_spent_table) %>% 
	mutate(`WFRC Model` = if_else(`WFRC Model` == "X", NA, `WFRC Model`)) %>% 
	mutate(Task = str_replace_all(Task, "\\\\u00b9", "\u00b9")) %>%
	mutate(Task = str_replace_all(Task, "\\\\u00b2", "\u00b2")) %>%
	skbl(align = c("l", "l", "c", "c")) %>% 
	add_header_above(c(" " = 2, "Hours Spent on Task" = 2)) %>% 
	kable_styling() %>% 
	collapse_rows(1:2) %>% 
	footnote(
		number = c(
			"This task was iterative and the \"common\" structure changed over time to reflect new analyses as they came up",
			"These analyses use the \"common\" structure directly and so took identical time and effort between the two models"
		)
	)

```

The overall time spent for ActivitySim is on par with that for the WFRC model, though there are a few important notes about this comparison:

First, the scenarios in ActivitySim were somewhat dependent on the outputs of the WFRC model.
ActivitySim depends on the WFRC model's travel skims, as ActivitySim does not perform network assignment and so is unable to determine congested travel times on its own.
In the Transit scenario, for example, the only change needed for ActivitySim was to use updated transit skims, which was extremely quick to implement.
However, these updated skims came from the results of the WFRC model's Transit scenario, and so in some sense the time spent for ActivitySim on this task should possibly include the time spent for the WFRC model.

Second, the tasks were divided between two research assistants largely in line with the model type.
This means that @tbl-time-spent is showing the time spent with each model type by a specific individual.
In other words, the difference within this table is not only the model type, but also the individual working on the task.
Any comparisons between the time spent on the two models should therefore take this into consideration.

One additional point to note is how the analyses were performed in each model.
The outputs of the WFRC model relevant to our analyses consist mainly of matrices listing the number of trips between zones.
There is a separate matrix for each mode and purpose, and so analyzing the data from the WFRC model requires making comparisons between several matrices for each scenario, and potentially aggregating values across different matrices.
The only output of ActivitySim relevant to our analyses is a table listing every trip made in the scenario, which includes information on person id, mode, time of day, purpose, etc.
There is therefore only one table per scenario that we used in our analyses, as this table contained all the necessary information for each analysis.
For example, to create the Non--home-based desire line plot for the WFRC model (@fig-lu-desire-nhb-cube), we took the Non--home-based trip matrices and took the difference between the Land Use and baseline scenario for each mode.
For the desire line plot in ActivitySim (@fig-lu-desire-asim), we took the table of trips and filtered the list to only persons whose home zone was in the new development.
We then had a list of trips made by residents of the new development and were able to aggregate these trips and create the desire line plot.
Both of these figures took roughly the same amount of effort to create, and the analysis in ActivitySim gives more detailed information than the equivalent analysis in the WFRC model.

## Recommendations

Our experience in this research runs counter to many of the commonly discussed "pain points" of ABM adoption.
Our ActivitySim implementation was no more computationally intensive than the WFRC model, we found relatively easy interoperability between the example San Francisco and Michigan ActivitySim implementations, and the amount of time and effort required to understand and configure ActivitySim was on the whole rather small.
Additionally, while ActivitySim may be more complicated "under the hood" than the WFRC model, the interpretation of ActivitySim is in some ways significantly simpler.
It is possible that these "pain points" are outdated, as there have not been many comparisons between model types in recent years (as discussed in @sec-literature-research-gap).

Our central recommendation, then, is for an agency considering transitioning to an ABM to recognize that some of the commonly-cited difficulties of ABMs may not actually be as relevant as initially thought.

There are, however, certainly still valid reasons for an agency to continue to use a trip-based model over an ABM.
Though in our experience the effort required to configure ActivitySim was not unreasonable, the effort was non-trivial.
An agency would need to spend time and effort to re-train its staff and modify its existing workflow pipeline.
Additionally, an agency switching to an ABM would lose conformity with previous analyses.
Comparing model results from before and after the transition could therefore be difficult, though this would depend on the specific comparisons desired.
In this research, we were for example able to make several direct comparisons between ActivitySim and the WFRC model (see Chapters [-@sec-landuse]--[-@sec-wfh]).

One crucial consideration to make is that ActivitySim does not perform network assignment.
Many agencies that currently use ActivitySim in fact use CUBE or other similar software to perform assignment, though there are also several open-source network assignment programs such as MATSim [@horni_multi-agent_2016] and AequilibraE [@aequilibrae] that are also in use.
Regardless of the software used for network assignment, an agency will need to determine how best to integrate assignment into their modeling workflow in order to use ActivitySim.
This issue is specific to ActivitySim, and other ABMs may incorporate network assignment directly.
However, even ActivitySim itself is designed to be extensible, and as discussed above it is relatively easy to modify ActivitySim's model pipeline to allow for adding model steps.
This extensibility also includes the ability to add custom pipeline steps, so it would be possible to add a feedback loop between network skims/accessibility calculations and network assignment.

An additional point worth noting is that the scenarios chosen and the analyses demonstrated in Chapters [-@sec-landuse]--[-@sec-wfh] are only examples.
The number of scenarios and analyses that we could theoretically create is limitless, and we chose scenarios and analyses that we thought would illustrate well the differences between model types.
A common trend, though, is that for roughly the same amount of effort, we were able to perform more in-depth analyses with ActivitySim compared to the WFRC model.
This further shows that ABMs are not necessarily more difficult to work with than trip-based models.

The goal of this research is not to determine unilaterally which model type an agency should use, nor is the goal even to specify exact criteria under which an ABM should be used over a trip-based model.
Rather, the research presents our experience with both model types as an illustration for agencies to reference in determining which model type to use.
We therefore encourage each agency to review our findings in the context of their individual circumstances, and then determine which model type will best fulfill their specific modeling needs.
