# Discussion {#sec-discussion}

{{< include _setup.qmd >}}

As outlined in the Literature Review and presented by Miller [@miller_current_2023], there are three reasons cited by agencies for delaying the adoption of activity-based models: increased demand for computational resources; complex methodological design and the lack of transferability; and additional complexity in analysis requiring specialized staff training.
We will address these in turn.

In terms of computational resources, all runs of the WFRC /MAG model were done on a Windows 10 computer with 2 Intel process with a base frequency of 2.2 GHz and 10 cores/20 threads each.
The WFRC model is configured for multiprocessing in its destination and mode choice steps, and was configured to use 16 threads for our scenario runs.
Notably, this is a specialized computer, but would not be prohibitively expensive to most agencies (indeed, WFRC has computers with similar specifications already).
Each scenario had a total runtime of 16â€“17 hours on this hardware, but removing the assignment steps and all but one trip distribution feedback loop -- as in, a single run of the demand model --- reduces the run time to approximately 10 hours.
A complete run of ActivitySim on the same hardware took approximately 13 hours; a single run of ActivitySim on a dedicated compute node with 360GB RAM but only 12 threads took roughly 5 hours.
A machine with these specifications would not be unattainable to a regional agency, either through cloud services or hardware purchase.
It is possible that the WFRC/MAG model is uniquely inefficient for a trip-based model, but careful configuration of hardware and software suggest that ActivitySim can complete in similar time if not less.

Another perceived difficulty is complex model design and the lack of transferability.
We found, however, the opposite with ActivitySim.
Though perhaps imperfect, the ActivitySim remote work module we imported from SEMCOG responded more naturally to the increased work from home scenario than the WFRC/MAG trip-based model.
Further, the design of the telecommuting and work from home modules in the trip-based WFRC/MAG model is considerably more complex to understand or to improve further.
The same can be said for the non-home-based trips in the land use scenario.
Perhaps more importantly, the two models do not show the same results for some fundamental equity analyses, as previously identified in other research [@bills_looking_2017] and illustrated here with the distribution of incomes of transit riders.
Which income distribution is "correct" may not matter so much as the fact that it is *different*, perhaps leading to drastically different winners or losers in equity analyses.
And important equity-related variables such as race or gender would be impossible to analyze the the WFRC/MAG model.

The final perceived difficulty relates to the time it would take staff to accomplish analyses.
We completed this analysis with student researchers that had little prior experience with travel demand models.
@tbl-time-spent shows the amount of time spent on creating and analyzing each scenario in both models.
These are approximations, as detailed time logs by task are not available.
The overall time spent for ActivitySim is on par with that for the WFRC model, though there are a few important notes about this comparison: First, the scenarios in ActivitySim were somewhat dependent on the outputs of the WFRC model.
In the Transit scenario, for example, the only change needed for ActivitySim was to use updated transit skims, which was extremely quick to implement.
Second, some tasks are shared across models, as we developed a shared data structure for the results of this project specifically.

```{r}
#| label: tbl-time-spent
#| tbl-cap: Estimated Time Spent on Modeling Tasks

targets::tar_read(time_spent_table) |> 
	mutate(`WFRC Model` = if_else(`WFRC Model` == "X", NA, `WFRC Model`)) |> 
	mutate(Task = str_replace_all(Task, "\\\\u00b9", "\u00b9")) |>
	mutate(Task = str_replace_all(Task, "\\\\u00b2", "\u00b2")) |>
	skbl(align = c("l", "l", "c", "c")) |> 
	add_header_above(c(" " = 2, "Hours Spent on Task" = 2)) |> 
	kable_styling() |> 
	collapse_rows(1:2) |> 
	kableExtra::footnote(
		number = c(
			"This task was iterative and the \"common\" structure changed over time to reflect new analyses as they came up",
			"These analyses use the \"common\" structure directly and so took identical time and effort between the two models"
		)
	)

```

## Limitations

A number of limitations exist in this research.
The most glaring perhaps is that the two models we are comparing are somewhat dependent on each other; as our ActivitySim implementation does not have a process to pass travel demand to a network and receive congested transport impedances back, we are reliant on the WFRC/MAG model's congested travel skims.
This prevents us from examining pricing scenarios or others that are frequently cited as being an important reasons for adopting activity-based models.
At the same time, however, this allows us to keep the focus of the analysis on the *demand* portions of the travel demand model, where the strong methodological contrasts lie.
A deeper weakness in our approach, however, is that our version of ActivitySim is not calibrated independently to targets derived from source survey data, and instead to the outputs of the WFRC/MAG model.
We have attempted to minimize the effect of this weakness by focusing on general differences rather than differences in forecast, but there may be lingering effects we do not anticipate or identify.

Many of the claims of activity-based models with regards to coherence --- for instance, that a vehicle cannot be used on a trip for which it is not available --- were not tested or proven in our model.
It would be helpful to develop performance statistics to test or compare these types of analyses.
